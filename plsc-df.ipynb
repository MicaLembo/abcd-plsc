{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main directory and target directory paths\n",
    "data_dir = \"./dset\"\n",
    "deriv_dir = \"./derivatives2\"\n",
    "os.makedirs(deriv_dir, exist_ok=True)\n",
    "csv_sub_dir = op.join(deriv_dir, \"csv_subset_dir\")\n",
    "os.makedirs(csv_sub_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the Data\n",
    "#### First, we want to select the ABCD variables from the large collection of ABCD csv files.\n",
    "#### Some of the variables will be selected at specific event years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that don't need to be controlled for age\n",
    "# Define the lists of filenames and variables to extract\n",
    "abcd_var = {\n",
    "    \"abcd\": {\n",
    "        \"abcd_y_lt\": [\"interview_age\", \"rel_family_id\", \"site_id_l\"],\n",
    "        \"abcd_p_demo\": [\n",
    "            \"demo_sex_v2\",\n",
    "            \"demo_ethn_v2\",\n",
    "            #\"demo_race_a_*\",\n",
    "            \"demo_prnt_age_v2\",\n",
    "            \"demo_prnt_gender_id_v2\",\n",
    "            \"demo_prnt_ethn_v2\",\n",
    "            #\"demo_prnt_race_a_*\",\n",
    "            \"demo_prnt_ed_v2_2yr_l\",\n",
    "            \"demo_prtnr_ed_v2_2yr_l\",\n",
    "            \"demo_comb_income_v2\",\n",
    "            \"demo_prnt_income_v2_l\",\n",
    "            \"demo_origin_v2\",\n",
    "            \"demo_biomother_v2\",\n",
    "            \"demo_biofather_v2\",\n",
    "            \"demo_matgrandm_v2\",\n",
    "            \"demo_matgrandf_v2\",\n",
    "            \"demo_patgrandm_v2\",\n",
    "            \"demo_patgrandf_v2\",\n",
    "        ],\n",
    "    },\n",
    "    \"led_l\": {\n",
    "        \"led_l_coi\": [\"reshist_addr1_coi_r_coi_nat\"],\n",
    "        \"led_l_nbhsoc\": [\"reshist_addr1_nanda_disadv_fac\"],\n",
    "        \"led_l_gi\": [\"reshist_addr1_gstat_h_queen\"],\n",
    "    },\n",
    "    \"ph_y\": {\n",
    "        \"ph_y_anthro\": [\"anthroheightcalc\", \"anthroweightcalc\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# variables that need to be controlled for specific years\n",
    "# Define the lists of filenames and shared eventname\n",
    "\n",
    "abcd_var_age = {\n",
    "    \"ce_y\": {\n",
    "        \"ce_y_meim\": {\n",
    "            \"eventname\": \"3_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"meim_ss_exp\",\n",
    "                \"meim_ss_com\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_y_via\": {\n",
    "            \"eventname\": \"3_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"via_ss_hc\",\n",
    "                \"via_ss_amer\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_y_macv\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"macv_y_ss_fs\",\n",
    "                \"macv_y_ss_fo\",\n",
    "                \"macv_y_ss_fr\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_y_dm\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"dim_y_ss_mean\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"ce_p\": {\n",
    "        \"ce_p_meim\": {\n",
    "            \"eventname\": \"3_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"meim_p_ss_exp\",\n",
    "                \"meim_p_ss_com\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_p_via\": {\n",
    "            \"eventname\": \"3_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"via_p_ss_hc\",\n",
    "                \"via_p_ss_amer\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_p_macv\": {\n",
    "            \"eventname\": \"2_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"macv_p_ss_fs\",\n",
    "                \"macv_p_ss_fo\",\n",
    "                \"macv_p_ss_fr\",\n",
    "            ],\n",
    "        },\n",
    "        \"ce_p_comc\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"comc_ss_cohesion_p\",\n",
    "                \"comc_ss_control_p\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"ph_y\": {\n",
    "        \"ph_y_yrb\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"physical_activity1_y\",\n",
    "            ],\n",
    "        },\n",
    "        \"ph_y_resp\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"resp_wheeze_yn_y\",\n",
    "                \"resp_pmcough_yn_y\",\n",
    "                \"resp_diagnosis_yn_y\",\n",
    "                \"resp_bronch_yn_y\",\n",
    "            ],\n",
    "        },\n",
    "        \"ph_y_mctq\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"mctq_sdweek_calc\",\n",
    "                \"mctq_msfsc_calc\",\n",
    "            ],\n",
    "        },\n",
    "        \"ph_y_bp\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"blood_pressure_sys_mean\",\n",
    "                \"blood_pressure_dia_mean\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"mh_p\": {\n",
    "        \"mh_p_cbcl\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"cbcl_scr_syn_internal_t\",\n",
    "                \"cbcl_scr_syn_external_t\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    # here I select RS data that is available at year 4\n",
    "    \"mri_y\": {\n",
    "        \"mri_y_rsfmr_cor_gp_gp\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"copy_entire_file\": True,\n",
    "        },\n",
    "        \"mri_y_adm_info\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"mri_info_manufacturer\",\n",
    "            ],\n",
    "        },\n",
    "        \"mri_y_qc_motion\": {\n",
    "            \"eventname\": \"4_year_follow_up_y_arm_1\",\n",
    "            \"columns_to_extract\": [\n",
    "                \"src_subject_id\",\n",
    "                \"eventname\",\n",
    "                \"rsfmri_meanmotion\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively find files in directories\n",
    "def find_files(directory):\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            yield os.path.join(dirpath, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through both dictionaries\n",
    "for category, files_and_vars in {**abcd_var, **abcd_var_age}.items():\n",
    "    for filename, vars_or_info in files_and_vars.items():\n",
    "        # Initialize processing parameters\n",
    "        found_file = False\n",
    "        copy_entire_file = False\n",
    "        columns_to_extract = []\n",
    "        eventname_filter = None\n",
    "\n",
    "        # Determine if it's from `abcd_var` or `abcd_var_age`\n",
    "        if isinstance(vars_or_info, dict):  # Logic for `abcd_var_age`\n",
    "            eventname_filter = vars_or_info[\"eventname\"]\n",
    "            copy_entire_file = vars_or_info.get(\"copy_entire_file\", False)\n",
    "            columns_to_extract = vars_or_info.get(\"columns_to_extract\", [])\n",
    "        else:  # Logic for `abcd_var`\n",
    "            vars_to_extract = vars_or_info\n",
    "\n",
    "        # Search for the file in all subdirectories of `data_dir`\n",
    "        for file_path in find_files(data_dir):\n",
    "            if filename + \".csv\" in file_path:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Handle processing logic based on dictionary type\n",
    "                if eventname_filter is not None:  # `abcd_var_age` logic\n",
    "                    df_filtered = df[df[\"eventname\"] == eventname_filter]\n",
    "                    if not copy_entire_file and columns_to_extract:\n",
    "                        df_filtered = df_filtered[columns_to_extract]\n",
    "                    df_subset = df_filtered\n",
    "                else:  # `abcd_var` logic\n",
    "                    # Ordered dictionary to maintain the order of columns\n",
    "                    columns_to_keep = OrderedDict()\n",
    "                    columns_to_keep[\"src_subject_id\"] = True\n",
    "                    columns_to_keep[\"eventname\"] = True\n",
    "\n",
    "                    for col in vars_to_extract:\n",
    "                        if \"*\" in col:\n",
    "                            # Use regex to match pattern\n",
    "                            regex_pattern = col.replace(\"*\", \".*\")\n",
    "                            matched_columns = list(\n",
    "                                df.filter(regex=regex_pattern).columns\n",
    "                            )\n",
    "                            for matched_col in matched_columns:\n",
    "                                columns_to_keep[matched_col] = True\n",
    "                        else:\n",
    "                            columns_to_keep[col] = True\n",
    "\n",
    "                    # Create subset dataframe with desired columns\n",
    "                    df_subset = df[list(columns_to_keep.keys())]\n",
    "\n",
    "                # Construct the destination path and filename\n",
    "                output_filename = f\"{filename}_subset.csv\"\n",
    "                output_path = os.path.join(csv_sub_dir, output_filename)\n",
    "\n",
    "                # Save the subset dataframe to the target directory\n",
    "                df_subset.to_csv(output_path, index=False)\n",
    "\n",
    "                print(f\"Saved {output_filename} to {csv_sub_dir}\")\n",
    "\n",
    "                found_file = True\n",
    "                break\n",
    "\n",
    "        if not found_file:\n",
    "            print(f\"File {filename}.csv not found in {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we want to foward fill some of the demographic data\n",
    "#### this ensures we have as much demo data as possible while making sure subject ID only appears once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the demo files\n",
    "file_names = [\n",
    "    \"abcd_y_lt_subset.csv\",\n",
    "    \"abcd_p_demo_subset.csv\",\n",
    "]\n",
    "\n",
    "# Array to store subject IDs if demo_ethn_v2 == 1 AND year 4 data available\n",
    "subject_ids = []\n",
    "\n",
    "# Loop over each file name\n",
    "for file_name in file_names:\n",
    "    # Define the path to the CSV file\n",
    "    file_path = op.join(csv_sub_dir, file_name)\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Forward fill within each 'src_subject_id' group\n",
    "    df = df.set_index(\"src_subject_id\").groupby(\"src_subject_id\").ffill().reset_index()\n",
    "\n",
    "    # Filter rows where 'eventname' is '4_year_follow_up_y_arm_1'\n",
    "    df = df[df[\"eventname\"] == \"4_year_follow_up_y_arm_1\"]\n",
    "\n",
    "    # Additional filtering for the 'abcd_p_demo_subset.csv' file\n",
    "    if file_name == \"abcd_p_demo_subset.csv\":\n",
    "        df = df[df[\"demo_ethn_v2\"] == 1]\n",
    "\n",
    "        # Save the subject IDs to the array\n",
    "        subject_ids = df[\"src_subject_id\"].tolist()\n",
    "\n",
    "    # Reset index and ensure 'src_subject_id' is preserved\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Save the processed DataFrame\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Print the array of subject IDs\n",
    "print(\"Filtered subject IDs:\", subject_ids)\n",
    "\n",
    "# Print the count of subject IDs\n",
    "print(\n",
    "    f\"Number of subject IDs w demo_ethn_v2 == 1 AND Y4 demographic data : N = {len(subject_ids)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use subject IDS to filter CSV files\n",
    "\n",
    "rs_subject_ids = []  # Array to store unique subject IDs with RS data\n",
    "\n",
    "for file_name in os.listdir(csv_sub_dir):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure we're only processing CSV files\n",
    "        file_path = os.path.join(csv_sub_dir, file_name)\n",
    "\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Keep only rows where 'src_subject_id' is in the subject_ids list\n",
    "        df_filtered = df[df[\"src_subject_id\"].isin(subject_ids)]\n",
    "\n",
    "        # Save the filtered DataFrame back to the same file\n",
    "        df_filtered.to_csv(file_path, index=False)\n",
    "\n",
    "        # print(f\"Filtered and saved {file_name}\")\n",
    "\n",
    "        if file_name == \"mri_y_rsfmr_cor_gp_gp_subset.csv\":\n",
    "            # Get the unique subject IDs\n",
    "            df_filtered = df_filtered.dropna()\n",
    "            \n",
    "            rs_subject_ids = df_filtered[\"src_subject_id\"].unique().tolist()\n",
    "\n",
    "            # Get the number of unique subject IDs\n",
    "            subject_ids_count = len(rs_subject_ids)\n",
    "\n",
    "            # Print the number of unique subject IDs\n",
    "            print(\n",
    "                f\"Number of unique subject IDs with RS data: {subject_ids_count}\"\n",
    "            )\n",
    "\n",
    "# Print the array of unique subject IDs\n",
    "print(f\"Subject IDs with RS data: {rs_subject_ids}\")\n",
    "\n",
    "for file_name in os.listdir(csv_sub_dir):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure we're only processing CSV files\n",
    "        file_path = os.path.join(csv_sub_dir, file_name)\n",
    "\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter rows where 'src_subject_id' is in the unique RS subject IDs list\n",
    "        df_filtered = df[df[\"src_subject_id\"].isin(rs_subject_ids)]\n",
    "\n",
    "        # Save the filtered DataFrame back to the same file\n",
    "        df_filtered.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Filtered and saved {file_name} with RS subject IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have filtered data, we want to create measure dataframes that will be used in PLSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(csv_sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize empty DataFrames for each category\n",
    "sociocult_df_Nan = pd.DataFrame()\n",
    "covariate_df_Nan = pd.DataFrame()\n",
    "rsfc_df_Nan = pd.DataFrame()\n",
    "phyhealth_df_Nan = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Function to merge CSV files on subject ID and remove 'eventname' column if it exists\n",
    "def merge_csv(file_path, df):\n",
    "    temp_df = pd.read_csv(file_path).replace([777.0, 999.0], np.nan)\n",
    "\n",
    "    # Remove 'eventname' column if it exists\n",
    "    if \"eventname\" in temp_df.columns:\n",
    "        temp_df = temp_df.drop(columns=[\"eventname\"])\n",
    "\n",
    "    # Merge on subject ID (assuming 'subject_id' is the column name for subject ID)\n",
    "    if df.empty:\n",
    "        return temp_df\n",
    "    else:\n",
    "        return pd.merge(df, temp_df, on=\"src_subject_id\", how=\"outer\")\n",
    "\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for files in os.listdir(csv_sub_dir):\n",
    "    print(files)\n",
    "    file_path = os.path.join(csv_sub_dir, files)\n",
    "\n",
    "    if files.startswith(\"ce\") or files.startswith(\"led\"):\n",
    "        sociocult_df_Nan = merge_csv(file_path, sociocult_df_Nan)\n",
    "    elif files.startswith((\"abcd\", \"mri_y_adm\", \"mri_y_qc\")):\n",
    "        covariate_df_Nan = merge_csv(file_path, covariate_df_Nan)\n",
    "    elif files.startswith(\"mri_y_rsfmr\"):\n",
    "        rsfc_df_Nan = merge_csv(file_path, rsfc_df_Nan)\n",
    "    elif files.startswith((\"mh\", \"ph\")):\n",
    "        phyhealth_df_Nan = merge_csv(file_path, phyhealth_df_Nan)\n",
    "\n",
    "# After merging, you can print or save the DataFrames as needed\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Sociocultural DataFrame:\")\n",
    "print(sociocult_df_Nan.head())\n",
    "\n",
    "print(\"\\nCovariate DataFrame:\")\n",
    "print(covariate_df_Nan.head())\n",
    "\n",
    "print(\"\\nPhysical Health DataFrame:\")\n",
    "print(phyhealth_df_Nan.head())\n",
    "\n",
    "print(\"\\nRSFC DataFrame:\")\n",
    "print(rsfc_df_Nan.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for saving\n",
    "sociocult_save_path = os.path.join(deriv_dir, \"sociocult_Nan.csv\")\n",
    "covariate_save_path = os.path.join(deriv_dir, \"covariate_Nan.csv\")\n",
    "phyhealth_save_path = os.path.join(deriv_dir, \"phyhealth_Nan.csv\")\n",
    "rsfc_save_path = os.path.join(deriv_dir, \"rsfc_Nan.csv\")\n",
    "\n",
    "# Save each DataFrame to a CSV file\n",
    "sociocult_df_Nan.to_csv(sociocult_save_path, index=False)\n",
    "covariate_df_Nan.to_csv(covariate_save_path, index=False)\n",
    "phyhealth_df_Nan.to_csv(phyhealth_save_path, index=False)\n",
    "rsfc_df_Nan.to_csv(rsfc_save_path, index=False)\n",
    "\n",
    "print(\"DataFrames have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a plot that shows percentage of missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_summary(df, df_name):\n",
    "\n",
    "    # Calculate the number of non-NaN values for each column (except the first column)\n",
    "    non_nan_counts = df.iloc[:, 1:].notna().sum()\n",
    "    # Calculate the percentage of missing data for each column (except the first column)\n",
    "    missing_percentage = df.iloc[:, 1:].isna().mean() * 100\n",
    "\n",
    "    # Create the summary DataFrame\n",
    "    summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Measure\": df.columns[1:],  # Exclude the first column\n",
    "            \"Number of Subjects\": non_nan_counts,  # Number of non-NaN values\n",
    "            \"Percentage Missing\": missing_percentage,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Determine if an asterisk should be added\n",
    "    summary[\"Above 5%\"] = summary[\"Percentage Missing\"].apply(\n",
    "        lambda x: \"*\" if x > 5 else \"\"\n",
    "    )\n",
    "\n",
    "    # Create a formatted string for the DataFrame summary\n",
    "    summary_str = f\"\\n{df_name} Missing Data Summary:\\n\"\n",
    "    summary_str += (\n",
    "        summary.to_string(\n",
    "            index=False,\n",
    "            columns=[\"Measure\", \"Number of Subjects\", \"Percentage Missing\", \"Above 5%\"],\n",
    "        )\n",
    "        + \"\\n\"\n",
    "    )\n",
    "\n",
    "    return summary, summary_str\n",
    "\n",
    "\n",
    "# Generate missing data summaries for each DataFrame\n",
    "sociocult_summary, sociocult_summary_str = missing_data_summary(\n",
    "    sociocult_df_Nan, \"Sociocultural DataFrame\"\n",
    ")\n",
    "covariate_summary, covariate_summary_str = missing_data_summary(\n",
    "    covariate_df_Nan, \"Covariate DataFrame\"\n",
    ")\n",
    "phyhealth_summary, phyhealth_summary_str = missing_data_summary(\n",
    "    phyhealth_df_Nan, \"Physical Health DataFrame\"\n",
    ")\n",
    "rsfc_summary, rsfc_summary_str = missing_data_summary(rsfc_df_Nan, \"RSFC DataFrame\")\n",
    "\n",
    "# Combine all summaries into one string\n",
    "all_summaries = (\n",
    "    sociocult_summary_str\n",
    "    + covariate_summary_str\n",
    "    + phyhealth_summary_str\n",
    "    + rsfc_summary_str\n",
    ")\n",
    "\n",
    "# Write the combined summaries to a text file\n",
    "with open(\"PLSC-missing_data.txt\", \"w\") as file:\n",
    "    file.write(all_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "\n",
    "\n",
    "def plot_missing_data_summary(summary, df_name, deriv_dir):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    barplot = sns.barplot(\n",
    "        x=\"Percentage Missing\", y=\"Measure\", data=summary, palette=\"viridis\"\n",
    "    )\n",
    "    plt.title(f\"{df_name} Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Percentage Missing (out of 589 subjects)\")\n",
    "    plt.ylabel(f\"ABCD {df_name} Measures\")\n",
    "    plt.xlim(0, 100)\n",
    "\n",
    "    # Add vertical lines\n",
    "    # plt.axvline(x=5, color=\"green\", linestyle=\"--\", label=\"5% Missing\")\n",
    "    # plt.axvline(x=10, color=\"red\", linestyle=\"--\", label=\"10% Missing\")\n",
    "\n",
    "    # Add custom legend with total number of subjects\n",
    "    plt.legend()\n",
    "\n",
    "    for index, row in summary.iterrows():\n",
    "        percentage_missing = format(row[\"Percentage Missing\"], \".2f\")\n",
    "        text_color = \"red\" if row[\"Percentage Missing\"] > 5 else \"black\"\n",
    "        barplot.annotate(\n",
    "            f\"{percentage_missing}%\",\n",
    "            xy=(row[\"Percentage Missing\"], index),\n",
    "            xytext=(20, 0),  # Move text slightly more to the right\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=text_color,\n",
    "        )\n",
    "\n",
    "    # Save the figure\n",
    "    file_path = os.path.join(deriv_dir, f\"{df_name.replace(' ', '_')}_missing_data.png\")\n",
    "    plt.tight_layout()  # Ensure a tight layout with some padding\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot and save the bar plots\n",
    "plot_missing_data_summary(sociocult_summary, \"Sociocultural\", deriv_dir)\n",
    "plot_missing_data_summary(covariate_summary, \"Covariate\", deriv_dir)\n",
    "plot_missing_data_summary(phyhealth_summary, \"Physical Health\", deriv_dir)\n",
    "plot_missing_data_summary(rsfc_summary, \"RSFC DataFrame\", deriv_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will remove all subjects with missing data to make final csvs for the PLSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify covariates we want to include\n",
    "\n",
    "cov_list = [\n",
    "    \"src_subject_id\",\n",
    "    \"interview_age\",\n",
    "    \"demo_sex_v2\",\n",
    "    \"demo_prnt_age_v2\",\n",
    "    \"demo_prnt_gender_id_v2\",\n",
    "    \"demo_prnt_ed_v2_2yr_l\",\n",
    "    \"demo_prtnr_ed_v2_2yr_l\",\n",
    "    \"demo_comb_income_v2\",\n",
    "    \"demo_prnt_income_v2_l\",\n",
    "    \"mri_info_manufacturer\",\n",
    "    \"rsfmri_meanmotion\",\n",
    "]\n",
    "covariate_df_Nan_filtered = covariate_df_Nan[cov_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any NaN values\n",
    "sociocult_df_cleaned = sociocult_df_Nan.dropna()\n",
    "covariate_df_cleaned = covariate_df_Nan_filtered.dropna()\n",
    "rsfc_df_cleaned = rsfc_df_Nan.dropna()\n",
    "\n",
    "print(sociocult_df_cleaned)\n",
    "print(covariate_df_cleaned)\n",
    "print(rsfc_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of subject IDs in both DataFrames\n",
    "# Get the intersection of subject IDs in all three DataFrames\n",
    "common_ids = (\n",
    "    set(sociocult_df_cleaned[\"src_subject_id\"])\n",
    "    .intersection(set(covariate_df_cleaned[\"src_subject_id\"]))\n",
    "    .intersection(set(rsfc_df_cleaned[\"src_subject_id\"]))\n",
    ")\n",
    "print(common_ids)\n",
    "\n",
    "# Count the number of common IDs\n",
    "print(\"Number of common subject IDs:\", len(common_ids))\n",
    "\n",
    "# Filter both DataFrames to keep only the rows with common subject IDs\n",
    "sociocult_df_final = sociocult_df_cleaned[\n",
    "    sociocult_df_cleaned[\"src_subject_id\"].isin(common_ids)\n",
    "]\n",
    "sociocult_df_final = sociocult_df_final.drop(columns=[\"src_subject_id\"])\n",
    "\n",
    "covariate_df_final = covariate_df_cleaned[\n",
    "    covariate_df_cleaned[\"src_subject_id\"].isin(common_ids)\n",
    "]\n",
    "rsfc_df_final = rsfc_df_cleaned[rsfc_df_cleaned[\"src_subject_id\"].isin(common_ids)]\n",
    "# Drop the src_subject_id column from rsfc_df_final\n",
    "rsfc_df_final = rsfc_df_final.drop(columns=[\"src_subject_id\"])\n",
    "\n",
    "\n",
    "print(sociocult_df_final)\n",
    "print(covariate_df_final)\n",
    "print(rsfc_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for saving\n",
    "sociocult_save_path = os.path.join(deriv_dir, \"sociocult.csv\")\n",
    "covariate_save_path = os.path.join(deriv_dir, \"covariate.csv\")\n",
    "rsfc_save_path = os.path.join(deriv_dir, \"rsfc.csv\")\n",
    "\n",
    "# Save each DataFrame to a CSV file\n",
    "sociocult_df_final.to_csv(sociocult_save_path, index=False)\n",
    "covariate_df_final.to_csv(covariate_save_path, index=False)\n",
    "rsfc_df_final.to_csv(rsfc_save_path, index=False)\n",
    "\n",
    "print(\"DataFrames have been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
